{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2 of DDR Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Will Train the Steps from Spectrograms of MP3 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of all of the step files\n",
    "step_files = list(Path(\"C:/Users/brent/Desktop/StepMania 5\").rglob(\"*.[dD][wW][iI]\"))\n",
    "\n",
    "#Get the list of all of the step files\n",
    "song_files = list(Path(\"C:/Users/brent/Desktop/StepMania 5\").rglob(\"*.[mM][pP][3]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#There are not equal amounts of mp3s and matching step files\n",
    "print(len(song_files), len(step_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We modify the code below to capture the gap and the bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song(path, title):\n",
    "    #Open File\n",
    "    text_file = open(path, \"r\")\n",
    "    lines = text_file.readlines()\n",
    "    text_file.close()\n",
    "    \n",
    "    #Combine all text into single line\n",
    "    song = \"\".join(lines)\n",
    "    \n",
    "    #Remove newline characters\n",
    "    song = re.sub('\\n', '', song)\n",
    "    \n",
    "    #Split on semicolon and then add the semicolons back into the respective lines\n",
    "    song = song.split(';')\n",
    "    song = [line+';' for line in song][:-1]\n",
    "    \n",
    "    #Remove lines that start with 2 // (some files had this for some reason)\n",
    "    song = [line for line in song if (line.find('//') == -1)]\n",
    "    \n",
    "    #Create a dataframe of the song\n",
    "    df = pd.DataFrame()\n",
    "    df[title] = song\n",
    "    return df\n",
    "\n",
    "def pull_all_step_patterns(song, row, path):\n",
    "    song = song[row].str.split(\":\", n = 3, expand = True)\n",
    "    \n",
    "    #Get BPM\n",
    "    bpm = song[song[0] == \"#BPM\"].iloc[0,1]\n",
    "    #Remove ;\n",
    "    bpm = float(bpm[:-1])\n",
    "    \n",
    "    #Get Gap\n",
    "    gap = song[song[0] == \"#GAP\"].iloc[0,1]\n",
    "    #Remove ;\n",
    "    gap = float(gap[:-1])\n",
    "    \n",
    "    song = song[song[0].isin([\"#SINGLE\",\"#SOLO\"])]\n",
    "    \n",
    "    song['4'] = bpm\n",
    "    song['5'] = gap\n",
    "    song['6'] = path\n",
    "    \n",
    "    return song\n",
    "\n",
    "    \n",
    "def join_all_step_patterns(step_files):\n",
    "    songs = pd.DataFrame()\n",
    "    for row, path in enumerate(step_files):\n",
    "        df = process_song(path, row)\n",
    "        df = pull_all_step_patterns(df, row, path)\n",
    "        \n",
    "        #songs = pd.merge(songs, df, left_index=True, right_index=True, how=\"outer\")\n",
    "        songs = pd.concat([songs,df])\n",
    "    \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = join_all_step_patterns(step_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate through step patterns and Specify location of mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs.reset_index()\n",
    "songs.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that all step files have matching mp3 files\n",
    "#Create a dataframe that has both the step file path as well as the mp3 path\n",
    "for index, row in songs.iterrows():\n",
    "    #Get location of each dwi file and then determine location of mp3 file\n",
    "    steppath = songs.iloc[index, 6]\n",
    "    songpath = Path(steppath.parent.as_posix() + '/' + steppath.stem + '.mp3')\n",
    "    \n",
    "    if songpath in song_files:\n",
    "        songs.loc[index, '7'] = songpath\n",
    "    else:\n",
    "        songs.loc[index, '7'] is None      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we remove the step files that don't have interpreted mp3's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs[~songs['7'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs.reset_index()\n",
    "songs.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spectrograms for Matching Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_spectrogram(path, gap):\n",
    "    #offset should be duration of gap specifided in .DWI FIle\n",
    "    #Gap is in milliseconds while offset is in seconds\n",
    "\n",
    "    #Choose the file to create the graphics\n",
    "    filename = path\n",
    "\n",
    "    #y, sr = librosa.load(filename,offset=30, duration=12.0)\n",
    "    y, sr = librosa.load(filename, offset=gap/1000)\n",
    "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "    librosa.frames_to_time(onset_frames, sr=sr)\n",
    "\n",
    "    o_env = librosa.onset.onset_strength(y, sr=sr)\n",
    "    times = librosa.frames_to_time(np.arange(len(o_env)), sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)\n",
    "    D = np.abs(librosa.stft(y))\n",
    "\n",
    "    #Create the spectrogram\n",
    "    plt.clf()\n",
    "    plt.axis('off')\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),x_axis='time', y_axis='log')\n",
    "    plt.savefig(Path('image')/(filename.stem+'_1.png'))\n",
    "\n",
    "    #Create a beat offset graph\n",
    "    plt.clf()\n",
    "    plt.axis('off')\n",
    "    plt.plot(times, o_env)\n",
    "    plt.savefig(Path('image')/(filename.stem+'_2.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This next block creates about 1500 spectrograms and takes a long time.  On the order of hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Iterate through each row of the dataframe and create both versions of the spectrogram.\n",
    "for index, row in songs.iterrows():\n",
    "    songpath = songs.iloc[index, 7]\n",
    "    gap = songs.iloc[index, 5]\n",
    "    \n",
    "    imagepath1 = Path('image' + '/' + songpath.stem + '_1.png')\n",
    "    imagepath2 = Path('image' + '/' + songpath.stem + '_2.png')\n",
    "\n",
    "    songs.loc[index, '8'] = imagepath1\n",
    "    songs.loc[index, '9'] = imagepath2\n",
    "    \n",
    "    #Generate the actual spectrograms\n",
    "    #Toggled Off because it has been previously run\n",
    "    #mp3_to_spectrogram(songpath, gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the final file that we will use for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.columns = ['mode','label','difficulty','text','bpm','gap','step_path','mp3_path','spectrogram_path','spectrogram_path2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#songs = songs[[1,3]]\n",
    "#songs.columns = ['label','text']\n",
    "\n",
    "#Split the song into characters with semicolons\n",
    "songs['text'] = songs['text'].apply(lambda x: \";\".join(x))\n",
    "\n",
    "#Remove the trailing semicolon as we can add it back in when we are done predicting songs\n",
    "songs['text'] = songs['text'].apply(lambda x: x[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_csv(\"spectrogram.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Will Create our Data Bunch from the Spectrogram Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('spectrogram.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use multi category label through use of ';' as a delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our databunch\n",
    "#We choose not to use any transforms as the images\n",
    "#were created in a uniform fashion from mp3s\n",
    "data = (ImageList.from_df(df=songs, path='.', cols = ['spectrogram_path'])\n",
    "        .split_by_rand_pct(valid_pct=0.2)\n",
    "        .label_from_df(cols=['text'],label_delim=';')\n",
    "        .transform(([],[]))\n",
    "        .databunch(bs=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet152, metrics=[mean_absolute_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(100,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram_multicategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet152, metrics=[mean_absolute_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('spectrogram_multicategory')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.train_ds.y.items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_ds.y.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Regular Category Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our databunch\n",
    "#We choose not to use any transforms as the images\n",
    "#were created in a uniform fashion from mp3s\n",
    "data = (ImageList.from_df(df=songs, path='.', cols = ['spectrogram_path'])\n",
    "        .split_by_rand_pct(valid_pct=0)\n",
    "        .label_from_df(cols=['text'])\n",
    "        .transform(([],[]))\n",
    "        .databunch(bs=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet152, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(100,1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('spectrogram2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Now Have Our Trained Model and Area Ready for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.load('spectrogram2')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(data.x[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
